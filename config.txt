//Environmnet varaibles setup in bashrc


export JAVA_HOME=$(readlink -f /usr/bin/java | sed "s:bin/java::")

export HADOOP_HOME=/usr/local/hadoop
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_OPTS="$HADOOP_OPTS -Djava.library.path=$HADOOP_HOME/lib/native"
export PATH=$PATH:$HADOOP_HOME/sbin
export PATH=$PATH:$HADOOP_HOME/bin
export HADOOP_INSTALL=$HADOOP_HOME
export HADOOP_CLASSPATH=$JAVA_HOME/lib/tools.jar
export YARN_HOME=$HADOOP_HOME

export HIVE_HOME=/usr/local/hive
export PATH=$PATH:$HIVE_HOME/bin

//hadoop-env.sh

export JAVA_HOME=export JAVA_HOME=$(readlink -f /usr/bin/java | sed "s:bin/java::")
export HADOOP_HOME=/usr/local/hadoop


//core-site.xml

<property>
<name>fs.defaultFS</name>
<value>hdfs://localhost:9000</value>
</property>

//hdfs-site.xml

<property>
<name>dfs.replication</name>
<value>1</value>
</property>

//mapred-site.xml

<property>
<name>mapreduce.framework.name</name>
<value>yarn</value>
</property>

//yarn-site.xml

<property>
<name>yarn.nodemanager.aux-services</name>
<value>mapreduce_shuffle</value>
</property>


//INSTALACAO
1 - sudo adduser hadoop
2 - sudo adduser hadoop sudo
3 - sudo apt update
4 - su - hadoop
5 - ssh localhost
6 - hdfs namenode -format
7 - hadoop namenode -format
8 - start-dfs.sh
9 - hdfs dfs -mkdir /tmp
10 - hdfs dfs -chmod g+w /tmp
9 - jps